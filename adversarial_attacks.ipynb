{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/HP/Downloads/robust/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading required NLTK data...\n",
            "✓ All libraries imported and NLTK data downloaded successfully\n"
          ]
        }
      ],
      "source": [
        "# !pip install textattack transformers torch\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from textattack.models.wrappers import HuggingFaceModelWrapper\n",
        "from textattack.attack_recipes import TextFoolerJin2019, DeepWordBugGao2018\n",
        "from textattack.attack_results import SuccessfulAttackResult\n",
        "\n",
        "# Download required NLTK data for TextAttack\n",
        "import nltk\n",
        "print(\"Downloading required NLTK data...\")\n",
        "nltk.download('averaged_perceptron_tagger_eng', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "\n",
        "print(\"✓ All libraries imported and NLTK data downloaded successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model: distilbert-base-uncased-finetuned-sst-2-english\n",
            "✓ Model loaded successfully\n",
            "Note: Using DistilBERT model which is typically more vulnerable to adversarial attacks\n"
          ]
        }
      ],
      "source": [
        "# Load sentiment analysis model\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "print(f\"Loading model: {model_name}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "model_wrapper = HuggingFaceModelWrapper(model, tokenizer)\n",
        "\n",
        "# Label mapping for this model (NEGATIVE=0, POSITIVE=1)\n",
        "labels = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "\n",
        "print(\"✓ Model loaded successfully\")\n",
        "print(\"Note: Using DistilBERT model which is typically more vulnerable to adversarial attacks\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prepared 20 test samples:\n",
            "1. This movie is really good and enjoyable!\n",
            "2. I absolutely love this amazing product!\n",
            "3. The food here is excellent and delicious.\n",
            "4. This book is fantastic and well written.\n",
            "5. The service was wonderful and friendly.\n",
            "6. I'm so happy with this purchase!\n",
            "7. This restaurant serves great food.\n",
            "8. The movie was entertaining and fun.\n",
            "9. This product works perfectly fine.\n",
            "10. I really enjoyed the show.\n",
            "11. This book is terrible and boring.\n",
            "12. The movie was awful and disappointing.\n",
            "13. The food tastes bad and cold.\n",
            "14. This product is broken and useless.\n",
            "15. The service was horrible and slow.\n",
            "16. I hate this stupid movie.\n",
            "17. This restaurant has terrible food.\n",
            "18. The book was boring and dull.\n",
            "19. This product is completely worthless.\n",
            "20. I'm disappointed with this purchase.\n"
          ]
        }
      ],
      "source": [
        "# Define test samples (larger set with clearer sentiment examples)\n",
        "test_texts = [\n",
        "    # Positive examples\n",
        "    \"This movie is really good and enjoyable!\",\n",
        "    \"I absolutely love this amazing product!\",\n",
        "    \"The food here is excellent and delicious.\",\n",
        "    \"This book is fantastic and well written.\",\n",
        "    \"The service was wonderful and friendly.\",\n",
        "    \"I'm so happy with this purchase!\",\n",
        "    \"This restaurant serves great food.\",\n",
        "    \"The movie was entertaining and fun.\",\n",
        "    \"This product works perfectly fine.\",\n",
        "    \"I really enjoyed the show.\",\n",
        "    \n",
        "    # Negative examples  \n",
        "    \"This book is terrible and boring.\",\n",
        "    \"The movie was awful and disappointing.\",\n",
        "    \"The food tastes bad and cold.\",\n",
        "    \"This product is broken and useless.\",\n",
        "    \"The service was horrible and slow.\",\n",
        "    \"I hate this stupid movie.\",\n",
        "    \"This restaurant has terrible food.\",\n",
        "    \"The book was boring and dull.\",\n",
        "    \"This product is completely worthless.\",\n",
        "    \"I'm disappointed with this purchase.\"\n",
        "]\n",
        "\n",
        "print(f\"Prepared {len(test_texts)} test samples:\")\n",
        "for i, text in enumerate(test_texts, 1):\n",
        "    print(f\"{i}. {text}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up attacks with relaxed constraints...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "textattack: Unknown if model of class <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ TextFooler configured with relaxed constraints for better success rate\n",
            "Remaining constraints: 2\n"
          ]
        }
      ],
      "source": [
        "# Setup attacks with modified constraints for better success rate\n",
        "from textattack.constraints.pre_transformation import RepeatModification, StopwordModification\n",
        "from textattack.constraints.semantics.sentence_encoders import UniversalSentenceEncoder\n",
        "\n",
        "print(\"Setting up attacks with relaxed constraints...\")\n",
        "\n",
        "# Create TextFooler attack with relaxed constraints\n",
        "textfooler_attack = TextFoolerJin2019.build(model_wrapper)\n",
        "\n",
        "# Relax some constraints to increase success rate\n",
        "# Remove the sentence encoder constraint which is often too strict\n",
        "constraints_to_remove = []\n",
        "for constraint in textfooler_attack.constraints:\n",
        "    if isinstance(constraint, UniversalSentenceEncoder):\n",
        "        constraints_to_remove.append(constraint)\n",
        "\n",
        "for constraint in constraints_to_remove:\n",
        "    textfooler_attack.constraints.remove(constraint)\n",
        "\n",
        "print(\"✓ TextFooler configured with relaxed constraints for better success rate\")\n",
        "print(f\"Remaining constraints: {len(textfooler_attack.constraints)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "textattack: Unknown if model of class <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting up attacks with relaxed constraints...\n",
            "Original constraints: 3\n",
            "Relaxed WordEmbeddingDistance threshold to 0.5\n",
            "Found UniversalSentenceEncoder constraint - will remove\n",
            "✓ TextFooler configured with relaxed constraints\n",
            "Remaining constraints: 2\n",
            "✓ Removed overly strict semantic similarity constraints\n"
          ]
        }
      ],
      "source": [
        "# Setup attacks with modified constraints for better success rate\n",
        "from textattack.constraints.pre_transformation import RepeatModification, StopwordModification\n",
        "from textattack.constraints.semantics.sentence_encoders import UniversalSentenceEncoder\n",
        "from textattack.constraints.semantics import WordEmbeddingDistance\n",
        "\n",
        "print(\"Setting up attacks with relaxed constraints...\")\n",
        "\n",
        "# Create TextFooler attack with relaxed constraints\n",
        "textfooler_attack = TextFoolerJin2019.build(model_wrapper)\n",
        "\n",
        "print(f\"Original constraints: {len(textfooler_attack.constraints)}\")\n",
        "\n",
        "# Relax constraints to increase success rate\n",
        "# Remove semantic similarity constraints that are often too strict\n",
        "constraints_to_remove = []\n",
        "for constraint in textfooler_attack.constraints:\n",
        "    # Remove sentence-level semantic constraints\n",
        "    if isinstance(constraint, UniversalSentenceEncoder):\n",
        "        constraints_to_remove.append(constraint)\n",
        "        print(\"Found UniversalSentenceEncoder constraint - will remove\")\n",
        "    # Relax word embedding distance constraints\n",
        "    elif isinstance(constraint, WordEmbeddingDistance):\n",
        "        # Keep it but reduce the threshold\n",
        "        constraint.min_cos_sim = 0.5  # Default is often 0.8-0.9, reduce to 0.5\n",
        "        print(f\"Relaxed WordEmbeddingDistance threshold to {constraint.min_cos_sim}\")\n",
        "\n",
        "for constraint in constraints_to_remove:\n",
        "    textfooler_attack.constraints.remove(constraint)\n",
        "\n",
        "print(f\"✓ TextFooler configured with relaxed constraints\")\n",
        "print(f\"Remaining constraints: {len(textfooler_attack.constraints)}\")\n",
        "print(\"✓ Removed overly strict semantic similarity constraints\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original predictions:\n",
            "'This movie is really good and enjoyable!...' → POSITIVE (1.000)\n",
            "'I absolutely love this amazing product!...' → POSITIVE (1.000)\n",
            "'The food here is excellent and delicious....' → POSITIVE (1.000)\n",
            "'This book is fantastic and well written....' → POSITIVE (1.000)\n",
            "'The service was wonderful and friendly....' → POSITIVE (1.000)\n",
            "'I'm so happy with this purchase!...' → POSITIVE (1.000)\n",
            "'This restaurant serves great food....' → POSITIVE (1.000)\n",
            "'The movie was entertaining and fun....' → POSITIVE (1.000)\n",
            "'This product works perfectly fine....' → POSITIVE (1.000)\n",
            "'I really enjoyed the show....' → POSITIVE (1.000)\n",
            "'This book is terrible and boring....' → NEGATIVE (1.000)\n",
            "'The movie was awful and disappointing....' → NEGATIVE (1.000)\n",
            "'The food tastes bad and cold....' → NEGATIVE (1.000)\n",
            "'This product is broken and useless....' → NEGATIVE (1.000)\n",
            "'The service was horrible and slow....' → NEGATIVE (1.000)\n",
            "'I hate this stupid movie....' → NEGATIVE (1.000)\n",
            "'This restaurant has terrible food....' → NEGATIVE (0.989)\n",
            "'The book was boring and dull....' → NEGATIVE (1.000)\n",
            "'This product is completely worthless....' → NEGATIVE (1.000)\n",
            "'I'm disappointed with this purchase....' → NEGATIVE (1.000)\n"
          ]
        }
      ],
      "source": [
        "# Helper function to get predictions\n",
        "def get_prediction(text):\n",
        "    \"\"\"Get model prediction for a text\"\"\"\n",
        "    predictions = model_wrapper([text])\n",
        "    predicted_class = predictions[0].argmax().item()\n",
        "    confidence = torch.softmax(predictions[0], dim=0).max().item()\n",
        "    \n",
        "    return {\n",
        "        'text': text,\n",
        "        'prediction': labels[predicted_class],\n",
        "        'confidence': confidence\n",
        "    }\n",
        "\n",
        "# Test original predictions\n",
        "print(\"Original predictions:\")\n",
        "for text in test_texts:\n",
        "    result = get_prediction(text)\n",
        "    print(f\"'{result['text'][:50]}...' → {result['prediction']} ({result['confidence']:.3f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running TextFooler attacks...\n",
            "\n",
            "--- Attack 1/20 ---\n",
            "Original: 'This movie is really good and enjoyable!' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 2/20 ---\n",
            "Original: 'I absolutely love this amazing product!' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 3/20 ---\n",
            "Original: 'The food here is excellent and delicious.' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 4/20 ---\n",
            "Original: 'This book is fantastic and well written.' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 5/20 ---\n",
            "Original: 'The service was wonderful and friendly.' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 6/20 ---\n",
            "Original: 'I'm so happy with this purchase!' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 7/20 ---\n",
            "Original: 'This restaurant serves great food.' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 8/20 ---\n",
            "Original: 'The movie was entertaining and fun.' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 9/20 ---\n",
            "Original: 'This product works perfectly fine.' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 10/20 ---\n",
            "Original: 'I really enjoyed the show.' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 11/20 ---\n",
            "Original: 'This book is terrible and boring.' → NEGATIVE (1.000)\n",
            "Adversarial: 'This book is spooky and annoy.' → POSITIVE (0.999)\n",
            "✓ SUCCESS - Prediction flipped!\n",
            "\n",
            "--- Attack 12/20 ---\n",
            "Original: 'The movie was awful and disappointing.' → NEGATIVE (1.000)\n",
            "Adversarial: 'Both movie was outrageous and sorrowful.' → POSITIVE (0.997)\n",
            "✓ SUCCESS - Prediction flipped!\n",
            "\n",
            "--- Attack 13/20 ---\n",
            "Original: 'The food tastes bad and cold.' → NEGATIVE (1.000)\n",
            "Adversarial: 'Both eat flavor injurious and cold.' → POSITIVE (0.544)\n",
            "✓ SUCCESS - Prediction flipped!\n",
            "\n",
            "--- Attack 14/20 ---\n",
            "Original: 'This product is broken and useless.' → NEGATIVE (1.000)\n",
            "Adversarial: 'This begets is broken and immaterial.' → POSITIVE (0.977)\n",
            "✓ SUCCESS - Prediction flipped!\n",
            "\n",
            "--- Attack 15/20 ---\n",
            "Original: 'The service was horrible and slow.' → NEGATIVE (1.000)\n",
            "Adversarial: 'The service was spooky and decelerate.' → POSITIVE (0.998)\n",
            "✓ SUCCESS - Prediction flipped!\n",
            "\n",
            "--- Attack 16/20 ---\n",
            "Original: 'I hate this stupid movie.' → NEGATIVE (1.000)\n",
            "Adversarial: 'I rancour this nutty photographed.' → POSITIVE (0.998)\n",
            "✓ SUCCESS - Prediction flipped!\n",
            "\n",
            "--- Attack 17/20 ---\n",
            "Original: 'This restaurant has terrible food.' → NEGATIVE (0.989)\n",
            "Adversarial: 'This restaurant has outrageous food.' → POSITIVE (1.000)\n",
            "✓ SUCCESS - Prediction flipped!\n",
            "\n",
            "--- Attack 18/20 ---\n",
            "Original: 'The book was boring and dull.' → NEGATIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 19/20 ---\n",
            "Original: 'This product is completely worthless.' → NEGATIVE (1.000)\n",
            "Adversarial: 'This product is completely immaterial.' → POSITIVE (0.999)\n",
            "✓ SUCCESS - Prediction flipped!\n",
            "\n",
            "--- Attack 20/20 ---\n",
            "Original: 'I'm disappointed with this purchase.' → NEGATIVE (1.000)\n",
            "Adversarial: 'I'm illusions with this purchase.' → POSITIVE (0.995)\n",
            "✓ SUCCESS - Prediction flipped!\n",
            "\n",
            "TextFooler Results: 9/20 successful attacks\n"
          ]
        }
      ],
      "source": [
        "# TextFooler Attack\n",
        "print(\"Running TextFooler attacks...\")\n",
        "# textfooler_attack already configured in previous cell with relaxed constraints\n",
        "\n",
        "textfooler_results = []\n",
        "\n",
        "for i, text in enumerate(test_texts):\n",
        "    print(f\"\\n--- Attack {i+1}/{len(test_texts)} ---\")\n",
        "    original = get_prediction(text)\n",
        "    print(f\"Original: '{text}' → {original['prediction']} ({original['confidence']:.3f})\")\n",
        "    \n",
        "    try:\n",
        "        attack_result = textfooler_attack.attack(text, 0)\n",
        "        \n",
        "        if isinstance(attack_result, SuccessfulAttackResult):\n",
        "            adversarial_text = attack_result.perturbed_text()\n",
        "            adversarial = get_prediction(adversarial_text)\n",
        "            \n",
        "            # Check if prediction flipped\n",
        "            prediction_flipped = original['prediction'] != adversarial['prediction']\n",
        "            \n",
        "            print(f\"Adversarial: '{adversarial_text}' → {adversarial['prediction']} ({adversarial['confidence']:.3f})\")\n",
        "            \n",
        "            if prediction_flipped:\n",
        "                print(\"✓ SUCCESS - Prediction flipped!\")\n",
        "                \n",
        "            textfooler_results.append({\n",
        "                'original': text,\n",
        "                'adversarial': adversarial_text,\n",
        "                'original_pred': original['prediction'],\n",
        "                'adversarial_pred': adversarial['prediction'],\n",
        "                'success': prediction_flipped\n",
        "            })\n",
        "        else:\n",
        "            print(\"✗ FAILED\")\n",
        "            textfooler_results.append({\n",
        "                'original': text,\n",
        "                'success': False\n",
        "            })\n",
        "    except Exception as e:\n",
        "        print(f\"✗ ERROR: {e}\")\n",
        "        textfooler_results.append({\n",
        "            'original': text,\n",
        "            'success': False\n",
        "        })\n",
        "\n",
        "successful_attacks = sum(1 for r in textfooler_results if r.get('success', False))\n",
        "print(f\"\\nTextFooler Results: {successful_attacks}/{len(test_texts)} successful attacks\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "textattack: Unknown if model of class <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running DeepWordBug attacks...\n",
            "\n",
            "--- Attack 1/20 ---\n",
            "Original: 'This movie is really good and enjoyable!' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 2/20 ---\n",
            "Original: 'I absolutely love this amazing product!' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 3/20 ---\n",
            "Original: 'The food here is excellent and delicious.' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 4/20 ---\n",
            "Original: 'This book is fantastic and well written.' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 5/20 ---\n",
            "Original: 'The service was wonderful and friendly.' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 6/20 ---\n",
            "Original: 'I'm so happy with this purchase!' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 7/20 ---\n",
            "Original: 'This restaurant serves great food.' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 8/20 ---\n",
            "Original: 'The movie was entertaining and fun.' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 9/20 ---\n",
            "Original: 'This product works perfectly fine.' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 10/20 ---\n",
            "Original: 'I really enjoyed the show.' → POSITIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 11/20 ---\n",
            "Original: 'This book is terrible and boring.' → NEGATIVE (1.000)\n",
            "Adversarial: 'This book is errible and boirng.' → POSITIVE (0.899)\n",
            "✓ SUCCESS - Prediction flipped!\n",
            "\n",
            "--- Attack 12/20 ---\n",
            "Original: 'The movie was awful and disappointing.' → NEGATIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 13/20 ---\n",
            "Original: 'The food tastes bad and cold.' → NEGATIVE (1.000)\n",
            "Adversarial: 'MThe food tasses kad and Ecold.' → POSITIVE (0.665)\n",
            "✓ SUCCESS - Prediction flipped!\n",
            "\n",
            "--- Attack 14/20 ---\n",
            "Original: 'This product is broken and useless.' → NEGATIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 15/20 ---\n",
            "Original: 'The service was horrible and slow.' → NEGATIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 16/20 ---\n",
            "Original: 'I hate this stupid movie.' → NEGATIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 17/20 ---\n",
            "Original: 'This restaurant has terrible food.' → NEGATIVE (0.989)\n",
            "Adversarial: 'This restaurant has trrible food.' → POSITIVE (0.998)\n",
            "✓ SUCCESS - Prediction flipped!\n",
            "\n",
            "--- Attack 18/20 ---\n",
            "Original: 'The book was boring and dull.' → NEGATIVE (1.000)\n",
            "✗ FAILED\n",
            "\n",
            "--- Attack 19/20 ---\n",
            "Original: 'This product is completely worthless.' → NEGATIVE (1.000)\n",
            "Adversarial: 'This product is completely worthleDs.' → POSITIVE (0.999)\n",
            "✓ SUCCESS - Prediction flipped!\n",
            "\n",
            "--- Attack 20/20 ---\n",
            "Original: 'I'm disappointed with this purchase.' → NEGATIVE (1.000)\n",
            "Adversarial: ''Im Vdisappointed with this purchase.' → POSITIVE (0.953)\n",
            "✓ SUCCESS - Prediction flipped!\n",
            "\n",
            "DeepWordBug Results: 5/20 successful attacks\n"
          ]
        }
      ],
      "source": [
        "# DeepWordBug Attack\n",
        "print(\"Running DeepWordBug attacks...\")\n",
        "deepwordbug_attack = DeepWordBugGao2018.build(model_wrapper)\n",
        "\n",
        "deepwordbug_results = []\n",
        "\n",
        "for i, text in enumerate(test_texts):\n",
        "    print(f\"\\n--- Attack {i+1}/{len(test_texts)} ---\")\n",
        "    original = get_prediction(text)\n",
        "    print(f\"Original: '{text}' → {original['prediction']} ({original['confidence']:.3f})\")\n",
        "    \n",
        "    try:\n",
        "        attack_result = deepwordbug_attack.attack(text, 0)\n",
        "        \n",
        "        if isinstance(attack_result, SuccessfulAttackResult):\n",
        "            adversarial_text = attack_result.perturbed_text()\n",
        "            adversarial = get_prediction(adversarial_text)\n",
        "            \n",
        "            # Check if prediction flipped\n",
        "            prediction_flipped = original['prediction'] != adversarial['prediction']\n",
        "            \n",
        "            print(f\"Adversarial: '{adversarial_text}' → {adversarial['prediction']} ({adversarial['confidence']:.3f})\")\n",
        "            \n",
        "            if prediction_flipped:\n",
        "                print(\"✓ SUCCESS - Prediction flipped!\")\n",
        "                \n",
        "            deepwordbug_results.append({\n",
        "                'original': text,\n",
        "                'adversarial': adversarial_text,\n",
        "                'original_pred': original['prediction'],\n",
        "                'adversarial_pred': adversarial['prediction'],\n",
        "                'success': prediction_flipped\n",
        "            })\n",
        "        else:\n",
        "            print(\"✗ FAILED\")\n",
        "            deepwordbug_results.append({\n",
        "                'original': text,\n",
        "                'success': False\n",
        "            })\n",
        "    except Exception as e:\n",
        "        print(f\"✗ ERROR: {e}\")\n",
        "        deepwordbug_results.append({\n",
        "            'original': text,\n",
        "            'success': False\n",
        "        })\n",
        "\n",
        "successful_attacks = sum(1 for r in deepwordbug_results if r.get('success', False))\n",
        "print(f\"\\nDeepWordBug Results: {successful_attacks}/{len(test_texts)} successful attacks\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Final Results\n",
        "# print(\"=\" * 50)\n",
        "# print(\"ATTACK RESULTS\")\n",
        "# print(\"=\" * 50)\n",
        "\n",
        "# # TextFooler successful attacks\n",
        "# tf_successful = [r for r in textfooler_results if r.get('success', False)]\n",
        "# print(f\"\\nTextFooler successful attacks: {len(tf_successful)}/{len(test_texts)}\")\n",
        "\n",
        "# for result in tf_successful:\n",
        "#     print(f\"\\nOriginal: '{result['original']}'\")\n",
        "#     print(f\"Adversarial: '{result['adversarial']}'\")\n",
        "#     print(f\"Prediction: {result['original_pred']} → {result['adversarial_pred']}\")\n",
        "\n",
        "# # DeepWordBug successful attacks  \n",
        "# dwb_successful = [r for r in deepwordbug_results if r.get('success', False)]\n",
        "# print(f\"\\n{'-'*50}\")\n",
        "# print(f\"DeepWordBug successful attacks: {len(dwb_successful)}/{len(test_texts)}\")\n",
        "\n",
        "# for result in dwb_successful:\n",
        "#     print(f\"\\nOriginal: '{result['original']}'\")\n",
        "#     print(f\"Adversarial: '{result['adversarial']}'\")\n",
        "#     print(f\"Prediction: {result['original_pred']} → {result['adversarial_pred']}\")\n",
        "\n",
        "# print(f\"\\n{'='*50}\")\n",
        "# print(f\"Total successful attacks: {len(tf_successful) + len(dwb_successful)}\")\n",
        "# print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
